# src/book/graph_book.py

"""
LangGraph ê¸°ë°˜ Book ì¶”ì²œ íŒŒì´í”„ë¼ì¸ (ë‹¨ìˆœí™” ë²„ì „).

êµ¬ì¡° ê°œìš”
---------
1) LLM Decider (llm_decider.decide_strategy_with_llm)
   - user_inputì„ ë°›ì•„ì„œ í˜„ì¬ ê°ì •, ì›í•˜ëŠ” ê°ì •, ì¥ë¥´, ì „ëµ ë“±ì„ JSONìœ¼ë¡œ íŒŒì‹±.
   - ê²°ê³¼ëŠ” state["decision"]ì— ì €ì¥.

2) Candidate Generation (ì½˜í…ì¸  ê¸°ë°˜ SBERTë§Œ ì‚¬ìš©)
   - BookRecommender.recommend_from_llm_decision(llm_decision, top_k, user_input, exclude_book_ids)
   - user_profileì˜ seen_booksë¥¼ ì´ìš©í•´ "ì´ë¯¸ ì½ì€ ì±…"ì€ ì œì™¸.
   - ê²°ê³¼ë¥¼ state["candidates"]ì— ì €ì¥.
   - CFRecommenderëŠ” ì´ˆê¸° ì¶”ì²œ(run_chat_llm_demo.get_initial_recommendations)ì—ì„œë§Œ ì‚¬ìš©.

3) LLM Reranker (llm_reranker.rerank_with_llm)
   - ì…ë ¥: user_input, llm_decision, candidates (+ user_top_genres; ë‚˜ì¤‘ì— í•„ìš” ì‹œ Phase 2ì—ì„œ ì •ë¦¬ ê°€ëŠ¥)
   - ì¶œë ¥: {
       "reranked": [ ... ì±… dict ... ],
       "natural_output": "ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ìì—°ì–´ ì¶”ì²œ ë¬¸ì¥"
     }
   - ê²°ê³¼ë¥¼ state["reranked"], state["natural_output"]ì— ì €ì¥.

4) run_book_recommendation()
   - ì™¸ë¶€(ì˜ˆ: CLI, API)ì—ì„œ í˜¸ì¶œí•˜ëŠ” í—¬í¼.
   - BookState ì´ˆê¸°í™” â†’ graph.invoke â†’ ìµœì¢… BookState ë°˜í™˜.
"""

from __future__ import annotations

import logging
from typing import Any, Dict, List, Optional
import os

from langgraph.graph import StateGraph, END

from src.common.state_types import BaseRecState
from src.config import (
    MAX_CANDIDATES_FOR_LLM,
)
from .recommender import BookRecommender
from .cf_recommender import CFRecommender
from . import llm_decider
from . import llm_reranker
from src.book.user_profile import get_user_profile

logger = logging.getLogger(__name__)


# ============================================================
# 1. State ì •ì˜
# ============================================================


class BookState(BaseRecState):
    """
    LangGraphì—ì„œ ì‚¬ìš©í•˜ëŠ” Book ë„ë©”ì¸ ìƒíƒœ íƒ€ì….

    í•„ë“œ
    ----
    user_input : ì‚¬ìš©ìê°€ ì…ë ¥í•œ ìì—°ì–´ ë¬¸ì¥
    user_id    : GoodBooks-10k ê¸°ì¤€ user_id (int)
    decision   : llm_deciderê°€ ë°˜í™˜í•œ JSON(dict)
    candidates : LLMì— ë³´ë‚´ê¸° ì „, ì „í†µ ì¶”ì²œ ì‹œìŠ¤í…œì´ ë½‘ì•„ ë†“ì€ í›„ë³´ ë¦¬ìŠ¤íŠ¸
    reranked   : LLM rerankerê°€ ìµœì¢…ì ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë§¤ê¸´ í›„ë³´ ë¦¬ìŠ¤íŠ¸
    natural_output : ì‚¬ìš©ìì—ê²Œ ë°”ë¡œ ë³´ì—¬ì¤„ í•œêµ­ì–´ ì¶”ì²œ ì„¤ëª…
    """

    user_input: str
    user_id: int
    decision: Dict[str, Any]
    candidates: List[Dict[str, Any]]
    reranked: List[Dict[str, Any]]
    natural_output: str


# ============================================================
# 2. ì „ì—­ ì‹±ê¸€í†¤ Recommender (lazy init)
# ============================================================

_content_rec: Optional[BookRecommender] = None
_cf_rec: Optional[CFRecommender] = None


def get_recommenders() -> tuple[BookRecommender, CFRecommender]:
    """
    BookRecommender / CFRecommenderë¥¼ lazy init í›„ ë°˜í™˜.

    - import ì‹œì ì— ë¬´ê±°ìš´ ì‘ì—…ì´ ëŒì§€ ì•Šë„ë¡ í•˜ê³ ,
      ì‹¤ì œë¡œ ì¶”ì²œì„ ì²˜ìŒ í˜¸ì¶œí•  ë•Œ í•œ ë²ˆë§Œ ì´ˆê¸°í™”ë˜ë„ë¡ ì„¤ê³„.
    """
    global _content_rec, _cf_rec

    if _content_rec is None:
        logger.info("[Graph] Initializing BookRecommender (content-based)")
        _content_rec = BookRecommender()

    if _cf_rec is None:
        logger.info("[Graph] Initializing CFRecommender (item-based CF)")
        # content_recì—ì„œ book_id universeë¥¼ ê°€ì ¸ì™€ CFì— ë„˜ê²¨ì¤Œ
        valid_book_ids = set(_content_rec.df["book_id"].unique())
        base_dir = os.path.dirname(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        )
        my_ratings_path = os.path.join(
            base_dir, "data", "goodbooks-10k", "my_ratings.csv"
        )
        _cf_rec = CFRecommender(
            min_ratings_per_user=1,
            min_ratings_per_item=1,
            max_items_for_similarity=None,
            valid_book_ids=valid_book_ids,
        )
        _cf_rec.load_data()
        _cf_rec.build_interaction_matrix()
        # item-based similarity ê³„ì‚° (ì´ˆê¸° ì¶”ì²œ ë“±ì—ì„œ ì‚¬ìš© ê°€ëŠ¥)
        _cf_rec.compute_item_similarity()

    return _content_rec, _cf_rec


# ============================================================
# 3. LangGraph ë…¸ë“œ ì •ì˜
# ============================================================


def parse_intent_node(state: BookState) -> BookState:
    """
    1ë‹¨ê³„: LLMìœ¼ë¡œ ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬
    - strategy (by_title / by_mood / ë“±)
    - mentioned_titles
    - mood_keywords, genres ë“±
    ì„ ì¶”ì¶œí•œë‹¤.
    """
    user_input = state.get("user_input", "")
    logger.debug("[Graph] parse_intent_node - user_input=%s", user_input)

    try:
        decision = llm_decider.decide_strategy_with_llm(user_input)
        state["decision"] = decision
    except Exception as e:
        logger.exception("[Graph] LLM decider error: %s", e)
        # ì‹¤íŒ¨ ì‹œ ìµœì†Œ êµ¬ì¡°ë¼ë„ ìœ ì§€
        state["decision"] = {
            "strategy": "by_mood",
            "mentioned_titles": [],
            "mood_keywords": [],
            "genres": [],
            "extra_constraints": [],
        }

    d = state["decision"]
    logger.info(
        "[LLM ë¶„ì„ ê²°ê³¼ ìš”ì•½]\n"
        "- strategy: %s\n"
        "- mentioned_titles: %s\n"
        "- mood_keywords: %s\n"
        "- genres: %s\n"
        "- extra_constraints: %s",
        d.get("strategy"),
        d.get("mentioned_titles"),
        d.get("mood_keywords"),
        d.get("genres"),
        d.get("extra_constraints"),
    )

    return state


def generate_candidates_node(state: BookState) -> BookState:
    """
    2ë‹¨ê³„: ì „í†µ ì¶”ì²œ ì‹œìŠ¤í…œìœ¼ë¡œ í›„ë³´ ì±… ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±.

    ğŸ”¹ í˜„ì¬ ë²„ì „ ëª©í‘œ:
      - ëŒ€í™”í˜• ì¶”ì²œì—ì„œëŠ” **ì½˜í…ì¸  ê¸°ë°˜(SBERT)** ë§Œ ì‚¬ìš©
      - CFëŠ” ì´ˆê¸° ì¶”ì²œ(user_idë§Œ ìˆì„ ë•Œ)ì—ì„œë§Œ ì‚¬ìš©
    """
    user_id = state.get("user_id")
    decision = state.get("decision", {})
    user_input = state.get("user_input", "")

    # BookRecommenderë§Œ ì‚¬ìš©
    content_rec, _ = get_recommenders()

    # (ë‹¹ì¥ì€ ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ seen_books / user_top_genres ì•ˆ ì”€)
    # í•„ìš”í•´ì§€ë©´ ë‚˜ì¤‘ì— ë‹¤ì‹œ ë¶™ì´ë©´ ë¨
    try:
        content_candidates = content_rec.recommend_from_llm_decision(
            llm_decision=decision,
            top_k=MAX_CANDIDATES_FOR_LLM,
            user_input=user_input,
        )
    except Exception as e:
        logger.exception("[Graph] content recommend_from_llm_decision error: %s", e)
        state["candidates"] = []
        return state

    # SBERT ì ìˆ˜ë¥¼ ê·¸ëŒ€ë¡œ hybrid_scoreì— ë³µì‚¬
    candidates: List[Dict[str, Any]] = []
    for c in content_candidates:
        score = float(c.get("score", c.get("content_score", 0.0)))
        candidates.append(
            {
                "book_id": int(c["book_id"]),
                "title": c.get("title"),
                "authors": c.get("authors"),
                "content_score": score,
                "hybrid_score": score,  # ì§€ê¸ˆì€ content-only
            }
        )

    candidates.sort(key=lambda x: x.get("hybrid_score", 0.0), reverse=True)
    state["candidates"] = candidates
    return state




def rerank_with_llm_node(state: BookState) -> BookState:
    """
    3ë‹¨ê³„: LLMìœ¼ë¡œ í›„ë³´ë“¤ì„ ê°ì •/ë¬´ë“œ/ì¡°ê±´ì— ë§ê²Œ ì¬ì •ë ¬í•˜ê³ ,
    ìì—°ì–´ ì¶”ì²œ ë¬¸ì¥(natural_output)ì„ ìƒì„±í•œë‹¤.
    """
    user_input = state.get("user_input", "")
    decision = state.get("decision", {})
    candidates = state.get("candidates", [])
    user_id = state.get("user_id")

    logger.debug(
        "[Graph] rerank_with_llm_node - #candidates=%d",
        len(candidates),
    )

    if not candidates:
        state["reranked"] = []
        state[
            "natural_output"
        ] = "ì§€ê¸ˆì€ ì¶”ì²œí•  ìˆ˜ ìˆëŠ” ì±… í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        return state

    # user_profileì—ì„œ top_genres ë‹¤ì‹œ í•œ ë²ˆ ê°€ì ¸ì™€ì„œ rerankerì— ë„˜ê¹€
    user_top_genres: List[str] = []
    if user_id is not None:
        try:
            profile = get_user_profile(int(user_id))
            user_top_genres = profile.get("top_genres", []) or []
        except Exception as e:
            logger.exception("[Graph] get_user_profile error in rerank node: %s", e)
            user_top_genres = []

    try:
        result = llm_reranker.rerank_with_llm(
            user_input=user_input,
            llm_decision=decision,
            candidates=candidates,
            user_top_genres=user_top_genres,
        )
        reranked = result.get("reranked", [])
        natural_output = result.get("natural_output", "").strip()

        state["reranked"] = reranked or candidates
        if natural_output:
            state["natural_output"] = natural_output
        else:
            titles = [
                c.get("title") for c in state["reranked"][:3] if c.get("title")
            ]
            if titles:
                state[
                    "natural_output"
                ] = f"ì§€ê¸ˆ ìƒí™©ì— ì–´ìš¸ë¦¬ëŠ” ì±…ìœ¼ë¡œëŠ” {', '.join(titles)} ë“±ì„ ì¶”ì²œë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            else:
                state[
                    "natural_output"
                ] = "ì‚¬ìš©ìë‹˜ì˜ ì·¨í–¥ì— ë§ëŠ” ì±… ëª‡ ê¶Œì„ ì¶”ì²œí•´ ë‘ì—ˆìŠµë‹ˆë‹¤."

    except Exception as e:
        logger.exception("[Graph] LLM reranker error: %s", e)
        state["reranked"] = candidates
        state[
            "natural_output"
        ] = "ì‹œìŠ¤í…œ ë‚´ë¶€ ì˜¤ë¥˜ë¡œ ì¸í•´ ë‹¨ìˆœ ì¶”ì²œ ìˆœì„œë¡œ ì±…ì„ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤. ì–‘í•´ ë¶€íƒë“œë¦½ë‹ˆë‹¤."

    # ğŸ”¹ ì—¬ê¸°ì„œ ê³µí†µìœ¼ë¡œ ì¸ì‚¬ë§ prefix ë¶™ì´ê¸°
    try:
        uid = state.get("user_id")
        first_title = None
        if state.get("reranked"):
            first_title = state["reranked"][0].get("title")

        if uid is not None and first_title:
            prefix = f"ì•ˆë…•í•˜ì„¸ìš” {uid}ë‹˜, ì˜¤ëŠ˜ì€ ã€{first_title}ã€ë¥¼ í¬í•¨í•´ ëª‡ ê¶Œì˜ ì±…ì„ ì¶”ì²œë“œë ¤ìš”.\n\n"
        elif uid is not None:
            prefix = f"ì•ˆë…•í•˜ì„¸ìš” {uid}ë‹˜, ì§€ê¸ˆì˜ ê¸°ë¶„ê³¼ ì·¨í–¥ì— ë§ëŠ” ì±…ë“¤ì„ ì¶”ì²œë“œë ¤ìš”.\n\n"
        else:
            prefix = ""

        state["natural_output"] = prefix + state.get("natural_output", "")
    except Exception as e:
        logger.exception("[Graph] greeting prefix error: %s", e)

    return state


# ============================================================
# 4. ê·¸ë˜í”„ êµ¬ì„± + í—¬í¼
# ============================================================


def build_book_graph():
    """
    BookStateë¥¼ ì‚¬ìš©í•˜ëŠ” LangGraph íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•˜ì—¬
    compile()ê¹Œì§€ ë§ˆì¹œ ê°ì²´ë¥¼ ë°˜í™˜í•œë‹¤.
    """
    graph = StateGraph(BookState)

    graph.add_node("parse_intent", parse_intent_node)
    graph.add_node("generate_candidates", generate_candidates_node)
    graph.add_node("rerank_with_llm", rerank_with_llm_node)

    graph.set_entry_point("parse_intent")

    graph.add_edge("parse_intent", "generate_candidates")
    graph.add_edge("generate_candidates", "rerank_with_llm")
    graph.add_edge("rerank_with_llm", END)

    app = graph.compile()
    return app


# ì „ì—­ ê·¸ë˜í”„ ì‹±ê¸€í†¤
_book_graph = build_book_graph()


def run_book_recommendation(user_input: str, user_id: int) -> BookState:
    """
    CLI / API ë“± ì™¸ë¶€ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì§„ì…ì .

    ì˜ˆ:
        state = run_book_recommendation("ì§€ê¸ˆ ìš°ìš¸í•œë° ìœ„ë¡œë˜ëŠ” íŒíƒ€ì§€ ì†Œì„¤ ì¶”ì²œ", user_id=123)
        print(state["natural_output"])
    """
    initial_state: BookState = {
        "user_input": user_input,
        "user_id": user_id,
        "decision": {},
        "candidates": [],
        "reranked": [],
        "natural_output": "",
    }

    final_state: BookState = _book_graph.invoke(initial_state)
    return final_state
